{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport math\nimport random\nimport subprocess\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom glob import glob\nfrom pathlib import Path\nfrom tabulate import tabulate\nfrom shutil import copy, copytree\nfrom typing import Optional, Dict\n\nimport tensorflow as tf\nfrom keras import layers\nimport keras.backend as K\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.utils import plot_model\nfrom keras.preprocessing import image\nfrom keras.applications import DenseNet121, ConvNeXtSmall\nfrom keras.metrics import Precision, Recall, AUC\nfrom keras.callbacks import LearningRateScheduler, EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-20T08:37:58.221992Z","iopub.execute_input":"2024-07-20T08:37:58.222362Z","iopub.status.idle":"2024-07-20T08:37:58.232188Z","shell.execute_reply.started":"2024-07-20T08:37:58.222335Z","shell.execute_reply":"2024-07-20T08:37:58.230873Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def download_and_extract(download_url, download_path, output_dir):\n    try:\n        check_dependencies()\n\n        # Download the file without progress display\n        subprocess.run([\"wget\", \"-q\", download_url, \"-O\", download_path], check=True)\n\n        # Check if the download was successful before proceeding\n        if os.path.exists(download_path):\n            # Create the output directory\n            os.makedirs(output_dir, exist_ok=True)\n\n            # Extract the contents\n            extract_command = [\"tar\", \"-xf\", download_path, \"-C\", output_dir]\n            subprocess.run(extract_command, check=True)\n\n            # Remove the tar file after extraction\n            os.remove(download_path)\n            print(\"Download and extraction completed successfully.\")\n        else:\n            print(\"Error: Failed to download the dataset.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error: {str(e)}\")\n        \ndef check_dependencies():\n    try:\n        subprocess.run([\"wget\", \"--version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n        subprocess.run([\"tar\", \"--version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"Error: Dependency check failed. {e}\")\n        raise","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:37:58.233982Z","iopub.execute_input":"2024-07-20T08:37:58.234361Z","iopub.status.idle":"2024-07-20T08:37:58.250401Z","shell.execute_reply.started":"2024-07-20T08:37:58.234291Z","shell.execute_reply":"2024-07-20T08:37:58.249581Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Variables\ndownload_url = \"https://data.caltech.edu/records/nyy15-4j048/files/256_ObjectCategories.tar\"\ndownload_path = \"/kaggle/working/256_ObjectCategories.tar\"\n# download_path = \"/content/256_ObjectCategories.tar\" # colab\noutput_dir = \"/kaggle/working/data\"\n# output_dir = \"/content/data\" # colab\n\n# Function call\ndownload_and_extract(download_url, download_path, output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:37:58.251405Z","iopub.execute_input":"2024-07-20T08:37:58.251660Z","iopub.status.idle":"2024-07-20T08:38:55.823427Z","shell.execute_reply.started":"2024-07-20T08:37:58.251621Z","shell.execute_reply":"2024-07-20T08:38:55.822441Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Download and extraction completed successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"data_path = Path(r\"/kaggle/working/data/256_ObjectCategories\") # for kaggle\n# data_path = Path(r\"/content/data/256_ObjectCategories\") # for colab\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:38:55.826029Z","iopub.execute_input":"2024-07-20T08:38:55.826339Z","iopub.status.idle":"2024-07-20T08:38:55.831098Z","shell.execute_reply.started":"2024-07-20T08:38:55.826313Z","shell.execute_reply":"2024-07-20T08:38:55.829918Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def count_images_per_class(path):\n    \"\"\"\n    Prints the number of images in each class in the dataset.\n\n    Parameters:\n    -----------\n    path: str\n        A string representing the path to the data.\n\n    Returns:\n    --------\n    None. Prints the number of images in each class to console.\n    \"\"\"\n\n    # Printing the header for the output.\n    print(f'{\"Classes\":>22} | {\"Images\":^6}')\n    print(\"=\"*40)\n\n    # Looping through each folder in the data path.\n    for folder in os.listdir(path):\n\n        # Counting the number of files in the current folder.\n        sample_size = len(os.listdir(path / folder))\n\n        # Printing the folder name and the number of files in it.\n        print(f\"{folder.strip():<23s}|{sample_size}\")\n\n# Call the function with the data path as an argument\ncount_images_per_class(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:38:55.832705Z","iopub.execute_input":"2024-07-20T08:38:55.833073Z","iopub.status.idle":"2024-07-20T08:38:55.875447Z","shell.execute_reply.started":"2024-07-20T08:38:55.833045Z","shell.execute_reply":"2024-07-20T08:38:55.874503Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"               Classes | Images\n========================================\n005.baseball-glove     |148\n052.crab-101           |85\n046.computer-monitor   |133\n070.fire-extinguisher  |84\n190.snake              |112\n078.fried-egg          |90\n048.conch              |103\n015.bonsai-101         |122\n073.fireworks          |100\n101.head-phones        |138\n092.grapes             |201\n044.comet              |121\n050.covered-wagon      |97\n233.tuning-fork        |100\n098.harp               |100\n226.traffic-light      |99\n252.car-side-101       |116\n003.backpack           |151\n043.coin               |124\n097.harmonica          |89\n185.skateboard         |103\n231.tripod             |112\n234.tweezer            |122\n016.boom-box           |91\n102.helicopter-101     |88\n160.pez-dispenser      |83\n167.pyramid            |86\n056.dog                |103\n067.eyeglasses         |83\n063.electric-guitar-101|122\n077.french-horn        |92\n065.elk                |101\n144.minotaur           |82\n196.spaghetti          |104\n257.clutter            |827\n204.sunflower-101      |80\n007.bat                |106\n191.sneaker            |111\n105.horse              |270\n239.washing-machine    |84\n021.breadmaker         |142\n011.billiards          |278\n002.american-flag      |97\n122.kayak              |103\n235.umbrella-101       |114\n090.gorilla            |212\n038.chimp              |110\n061.dumb-bell          |102\n229.tricycle           |95\n089.goose              |110\n013.birdbath           |98\n230.trilobite-101      |94\n242.watermelon         |93\n023.bulldozer          |110\n154.palm-tree          |103\n119.jesus-christ       |87\n159.people             |209\n200.stained-glass      |100\n208.swiss-army-knife   |109\n036.chandelier-101     |106\n054.diamond-ring       |118\n058.doorknob           |93\n045.computer-keyboard  |85\n034.centipede          |100\n074.flashlight         |115\n100.hawksbill-101      |93\n256.toad               |108\n163.playing-card       |90\n032.cartman            |101\n222.tombstone          |91\n175.roulette-wheel     |83\n120.joy-stick          |130\n215.telephone-box      |84\n245.windmill           |91\n104.homer-simpson      |97\n251.airplanes-101      |800\n121.kangaroo-101       |82\n151.ostrich            |109\n218.tennis-racket      |81\n157.pci-card           |105\n240.watch-101          |201\n243.welding-mask       |90\n051.cowboy-hat         |114\n201.starfish-101       |81\n225.tower-pisa         |90\n047.computer-mouse     |94\n091.grand-piano-101    |95\n040.cockroach          |124\n221.tomato             |103\n110.hourglass          |85\n213.teddy-bear         |101\n216.tennis-ball        |98\n099.harpsichord        |80\n126.ladder             |242\n250.zebra              |96\n183.sextant            |100\n182.self-propelled-lawn-mower|120\n203.stirrups           |91\n149.necktie            |103\n027.calculator         |100\n232.t-shirt            |358\n057.dolphin-101        |106\n009.bear               |102\n116.iguana             |107\n132.light-house        |190\n255.tennis-shoes       |103\n187.skyscraper         |95\n095.hamburger          |86\n247.xylophone          |92\n152.owl                |120\n166.praying-mantis     |92\n029.cannon             |103\n173.rifle              |106\n236.unicorn            |97\n109.hot-tub            |156\n192.snowmobile         |112\n037.chess-board        |120\n238.video-projector    |97\n150.octopus            |111\n158.penguin            |149\n153.palm-pilot         |93\n227.treadmill          |147\n041.coffee-mug         |87\n039.chopsticks         |85\n184.sheet-music        |84\n198.spider             |109\n143.minaret            |130\n055.dice               |98\n141.microscope         |117\n025.cactus             |114\n147.mushroom           |202\n211.tambourine         |95\n107.hot-air-balloon    |89\n202.steering-wheel     |97\n161.photocopier        |103\n206.sushi              |98\n020.brain-101          |83\n139.megaphone          |86\n069.fighter-jet        |99\n134.llama-101          |119\n028.camel              |110\n118.iris               |108\n180.screwdriver        |102\n197.speed-boat         |100\n142.microwave          |107\n137.mars               |156\n108.hot-dog            |85\n024.butterfly          |112\n079.frisbee            |99\n080.frog               |116\n193.soccer-ball        |174\n207.swan               |115\n156.paper-shredder     |96\n094.guitar-pick        |104\n071.fire-hydrant       |99\n140.menorah-101        |89\n086.golden-gate-bridge |80\n001.ak47               |98\n064.elephant-101       |131\n066.ewer-101           |83\n177.saturn             |96\n031.car-tire           |90\n178.school-bus         |98\n114.ibis-101           |120\n127.laptop-101         |128\n138.mattress           |192\n169.radio-telescope    |92\n253.faces-easy-101     |435\n174.rotary-phone       |84\n172.revolver-101       |99\n128.lathe              |105\n189.snail              |119\n010.beer-mug           |94\n254.greyhound          |95\n129.leopards-101       |190\n188.smokestack         |88\n103.hibiscus           |111\n170.rainbow            |102\n112.human-skeleton     |84\n237.vcr                |90\n220.toaster            |94\n019.boxing-glove       |124\n115.ice-cream-cone     |88\n004.baseball-bat       |127\n224.touring-bike       |110\n214.teepee             |139\n081.frying-pan         |95\n030.canoe              |104\n241.waterfall          |95\n117.ipod               |121\n194.socks              |112\n155.paperclip          |92\n033.cd                 |102\n096.hammock            |285\n186.skunk              |81\n209.sword              |102\n181.segway             |100\n145.motorbikes-101     |798\n006.basketball-hoop    |90\n162.picnic-table       |91\n113.hummingbird        |116\n249.yo-yo              |100\n012.binoculars         |216\n228.triceratops        |95\n248.yarmulke           |84\n022.buddha-101         |97\n076.football-helmet    |84\n072.fire-truck         |118\n244.wheelbarrow        |91\n133.lightning          |136\n135.mailbox            |93\n068.fern               |110\n210.syringe            |111\n130.license-plate      |91\n125.knife              |101\n199.spoon              |105\n176.saddle             |110\n018.bowling-pin        |101\n212.teapot             |136\n060.duck               |87\n042.coffin             |87\n123.ketch-101          |111\n075.floppy-disk        |83\n049.cormorant          |106\n217.tennis-court       |105\n148.mussels            |174\n131.lightbulb          |92\n124.killer-whale       |91\n111.house-fly          |84\n084.giraffe            |84\n017.bowling-ball       |104\n164.porcupine          |101\n026.cake               |106\n179.scorpion-101       |80\n085.goat               |112\n093.grasshopper        |112\n136.mandolin           |93\n087.goldfish           |93\n053.desk-globe         |82\n246.wine-bottle        |101\n106.horseshoe-crab     |87\n146.mountain-bike      |82\n219.theodolite         |84\n082.galaxy             |81\n205.superman           |87\n195.soda-can           |87\n083.gas-pump           |95\n035.cereal-box         |87\n168.raccoon            |140\n059.drinking-straw     |83\n014.blimp              |86\n062.eiffel-tower       |83\n008.bathtub            |232\n223.top-hat            |80\n165.pram               |88\n171.refrigerator       |84\n088.golf-ball          |98\n","output_type":"stream"}]},{"cell_type":"code","source":" def prepare_data(path: str, b_size: int) -> tuple:\n    \"\"\"Prepares training, validation, and test dataframes along with their respective steps.\n\n    Args:\n        path (str): The path to the directory containing the data.\n        b_size (int): The batch size for training.\n\n    Returns:\n        tuple: A tuple containing the training dataframe, validation dataframe, test dataframe,\n        training steps, validation steps, and test steps.\n    \"\"\"\n    file_paths = []\n    labels = []\n\n    for claass in sorted(os.listdir(path)):\n        c_pth = os.path.join(path, claass)\n\n        for file in os.listdir(c_pth):\n            file_path = os.path.join(c_pth, file)\n            file_paths.append(file_path)\n            labels.append(claass)\n\n    print(f\"Files: {len(file_paths)}\\nLabels: {len(labels)}\\n\")\n\n    files_series = pd.Series(file_paths, name=\"file_paths\")\n    labels_series = pd.Series(labels, name=\"labels\")\n\n    d = pd.concat([files_series, labels_series], axis=1)\n\n    train_d, test_data_d = train_test_split(d, test_size=.2, stratify=d.labels, random_state=81)\n    train_d, valid_d = train_test_split(train_d, test_size=.2, stratify=train_d.labels, random_state=81)\n\n    print(f\"Training Data: {train_d.shape[0]} samples\\nTesting Data: {test_data_d.shape[0]} samples\\nValidation Data: {valid_d.shape[0]} samples\\n\")\n\n    return d, labels, train_d, valid_d, test_data_d\n\nBATCH_SIZE = 32\ndf, labels, train_df, valid_df, test_df = prepare_data(data_path, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:38:55.876597Z","iopub.execute_input":"2024-07-20T08:38:55.876929Z","iopub.status.idle":"2024-07-20T08:38:56.077865Z","shell.execute_reply.started":"2024-07-20T08:38:55.876902Z","shell.execute_reply":"2024-07-20T08:38:56.076832Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Files: 30609\nLabels: 30609\n\nTraining Data: 19589 samples\nTesting Data: 6122 samples\nValidation Data: 4898 samples\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef load_data(df, b_size=BATCH_SIZE, shuffle=True, random_state=81, workers=1):\n    generator = ImageDataGenerator(\n        rescale=1 / 255.,\n    )\n\n    data = generator.flow_from_dataframe(\n        df,\n        x_col=\"file_paths\",\n        y_col=\"labels\",\n        target_size=(224, 224),\n        class_mode=\"categorical\",\n        shuffle=shuffle,\n        batch_size=b_size,\n        seed=random_state,\n        workers=workers\n    )\n\n    # Print a warning for invalid filenames\n    invalid_filenames = df.loc[~df['file_paths'].isin(data.filenames), 'file_paths']\n    if not invalid_filenames.empty:\n        print(\"Warning: Invalid filenames found and will be ignored:\", invalid_filenames.tolist())\n\n    return data\n\n# Load the training, validation, and test data with consistent random_state\ntrain_data = load_data(train_df)\nvalid_data = load_data(valid_df, shuffle=False)\ntest_data = load_data(test_df, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:38:56.079273Z","iopub.execute_input":"2024-07-20T08:38:56.079724Z","iopub.status.idle":"2024-07-20T08:38:56.491620Z","shell.execute_reply.started":"2024-07-20T08:38:56.079667Z","shell.execute_reply":"2024-07-20T08:38:56.490827Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Found 19587 validated image filenames belonging to 257 classes.\nWarning: Invalid filenames found and will be ignored: ['/kaggle/working/data/256_ObjectCategories/198.spider/RENAME2', '/kaggle/working/data/256_ObjectCategories/056.dog/greg']\nFound 4898 validated image filenames belonging to 257 classes.\nFound 6122 validated image filenames belonging to 257 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model = ConvNeXtSmall(weights='imagenet', include_top=False)\nbase_model.trainable = True\ninput_layer = Input(shape=(224, 224, 3))\nx = base_model(input_layer)\nx = GlobalAveragePooling2D()(x)\noutput_layer = Dense(257, activation='sigmoid')(x)\n\nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:06:45.971784Z","iopub.execute_input":"2024-07-20T09:06:45.972769Z","iopub.status.idle":"2024-07-20T09:06:48.265716Z","shell.execute_reply.started":"2024-07-20T09:06:45.972729Z","shell.execute_reply":"2024-07-20T09:06:48.264728Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_19\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_23 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ convnext_small (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │    \u001b[38;5;34m49,454,688\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m)            │       \u001b[38;5;34m197,633\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ convnext_small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">49,454,688</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,633</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,652,321\u001b[0m (189.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,652,321</span> (189.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,652,321\u001b[0m (189.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,652,321</span> (189.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\ndef create_metrics():\n    \"\"\"\n    Creates instances of various metrics for evaluating model performance.\n    \"\"\"\n    @tf.function\n    def f1_score(y_true, y_pred):\n        \"\"\"Calculates the F1 score.\"\"\"\n        tp = true_positive(y_true, y_pred)\n        fp = false_positive(y_true, y_pred)\n        fn = false_negative(y_true, y_pred)\n\n        precision = tp / (tp + fp + K.epsilon())\n        recall = tp / (tp + fn + K.epsilon())\n\n        return 2 * (precision * recall) / (precision + recall + K.epsilon())\n\n    @tf.function\n    def specificity(y_true, y_pred):\n        \"\"\"Calculates the specificity.\"\"\"\n        tn = true_negative(y_true, y_pred)\n        fp = false_positive(y_true, y_pred)\n\n        return tn / (tn + fp + K.epsilon())\n\n    @tf.function\n    def sensitivity(y_true, y_pred):\n        \"\"\"Calculates the sensitivity.\"\"\"\n        tp = true_positive(y_true, y_pred)\n        fn = false_negative(y_true, y_pred)\n\n        return tp / (tp + fn + K.epsilon())\n\n    @tf.function\n    def mcc(y_true, y_pred):\n        \"\"\"\n        Calculates the Matthews correlation coefficient (MCC).\n        \n        This approach allows for a nuanced assessment of the model's ability to distinguish\n        between different classes, making it particularly valuable in scenarios where classes\n        may have varying levels of significance.\n        \n        \"\"\"\n        tp = true_positive(y_true, y_pred)\n        tn = true_negative(y_true, y_pred)\n        fp = false_positive(y_true, y_pred)\n        fn = false_negative(y_true, y_pred)\n\n        numerator = (tp * tn - fp * fn)\n        denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n\n        return numerator / (denominator + K.epsilon())\n\n    @tf.function\n    def true_positive(y_true, y_pred):\n        \"\"\"Calculates the number of true positives.\"\"\"\n        y_pred_pos, _, y_pos, _ = calculate_confusion_matrix(y_true, y_pred)\n        return K.sum(y_pos * y_pred_pos)\n\n    @tf.function\n    def false_positive(y_true, y_pred):\n        \"\"\"Calculates the number of false positives.\"\"\"\n        y_pred_pos, _, _, y_neg = calculate_confusion_matrix(y_true, y_pred)\n        return K.sum(y_neg * y_pred_pos)\n\n    @tf.function\n    def false_negative(y_true, y_pred):\n        \"\"\"Calculates the number of false negatives.\"\"\"\n        _, y_pred_neg, y_pos, _ = calculate_confusion_matrix(y_true, y_pred)\n        return K.sum(y_pos * y_pred_neg)\n\n    @tf.function\n    def true_negative(y_true, y_pred):\n        \"\"\"Calculates the number of true negatives.\"\"\"\n        _, y_pred_neg, _, y_neg = calculate_confusion_matrix(y_true, y_pred)\n        return K.sum(y_neg * y_pred_neg)\n\n    @tf.function\n    def calculate_confusion_matrix(y_true, y_pred):\n        \"\"\"Calculates the components of the confusion matrix.\"\"\"\n        y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n        y_pred_neg = 1 - y_pred_pos\n        y_pos = K.round(K.clip(y_true, 0, 1))\n        y_neg = 1 - y_pos\n        return y_pred_pos, y_pred_neg, y_pos, y_neg\n\n    precision_metric = Precision()\n    recall_metric = Recall()\n    f1_score_metric = f1_score\n    specificity_metric = specificity\n    sensitivity_metric = sensitivity\n    mcc_metric = mcc\n    auc_metric = AUC()\n\n    return (\n        precision_metric,\n        recall_metric,\n        f1_score_metric,\n        specificity_metric,\n        sensitivity_metric,\n        mcc_metric,\n        auc_metric,\n    )\n\ncustom_metrics = create_metrics()\n\n# precision_metric, recall_metric, f1_score_metric, specificity_metric, sensitivity_metric, mcc_metric, auc_metric = custom_metrics","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:06:48.267699Z","iopub.execute_input":"2024-07-20T09:06:48.267998Z","iopub.status.idle":"2024-07-20T09:06:48.302618Z","shell.execute_reply.started":"2024-07-20T09:06:48.267975Z","shell.execute_reply":"2024-07-20T09:06:48.301780Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class TimeCallback(tf.keras.callbacks.Callback):\n    \"\"\"Custom callback to record epoch times and total training time.\"\"\"\n\n    def on_train_begin(self, logs=None):\n        \"\"\"Initialize training start time and epoch times.\"\"\"\n        self.train_start_time = time.perf_counter()\n        self.epoch_times = []\n\n    def on_epoch_begin(self, epoch, logs=None):\n        \"\"\"Record start time of each epoch.\"\"\"\n        self.epoch_start_time = time.perf_counter()\n\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Calculate and store epoch time.\"\"\"\n        epoch_time = time.perf_counter() - self.epoch_start_time\n        self.epoch_times.append(epoch_time)\n\n    def on_train_end(self, logs=None):\n        \"\"\"Calculate total training time.\"\"\"\n        self.total_train_time = time.perf_counter() - self.train_start_time\n\ntime_callback = TimeCallback()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:06:48.303814Z","iopub.execute_input":"2024-07-20T09:06:48.304157Z","iopub.status.idle":"2024-07-20T09:06:48.311046Z","shell.execute_reply.started":"2024-07-20T09:06:48.304122Z","shell.execute_reply":"2024-07-20T09:06:48.310143Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:06:48.312868Z","iopub.execute_input":"2024-07-20T09:06:48.313138Z","iopub.status.idle":"2024-07-20T09:06:48.324888Z","shell.execute_reply.started":"2024-07-20T09:06:48.313116Z","shell.execute_reply":"2024-07-20T09:06:48.323954Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\n\nlearningRate = 1e-4\ndecayRate = 0.97\n\ndef lr_schedule(epoch):\n    if epoch < 2:\n        return learningRate\n    else:\n        return learningRate * decayRate ** epoch\n\nlearning_callback = LearningRateScheduler(lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:06:48.467003Z","iopub.execute_input":"2024-07-20T09:06:48.467376Z","iopub.status.idle":"2024-07-20T09:06:48.473585Z","shell.execute_reply.started":"2024-07-20T09:06:48.467346Z","shell.execute_reply":"2024-07-20T09:06:48.472364Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ncustom_metrics = list(create_metrics())\ncustom_metrics.append(\"accuracy\")\n\nmodel.compile(\n    optimizer=Adam(learning_rate=learningRate),\n    loss='categorical_crossentropy',\n    metrics=custom_metrics\n)\n\nhistory = model.fit(\n    train_data,\n    validation_data=valid_data,\n    epochs=30,\n    callbacks=[time_callback, early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:06:48.972776Z","iopub.execute_input":"2024-07-20T09:06:48.973491Z","iopub.status.idle":"2024-07-20T09:43:39.873172Z","shell.execute_reply.started":"2024-07-20T09:06:48.973460Z","shell.execute_reply":"2024-07-20T09:43:39.872208Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721466501.880517     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.881061     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.881554     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.882706     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.883155     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.883599     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.884047     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.884491     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.885025     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.885500     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.885965     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.886431     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.886911     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.887383     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.887887     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.888328     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.888764     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.889204     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.889649     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.890080     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.890517     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.890976     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.891430     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.891888     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.892356     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.892857     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.893265     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.893712     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.894186     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.894624     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.897016     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.897851     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.899023     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.899763     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.900417     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.901076     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.901719     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.902377     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.903144     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.903830     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.904436     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.905133     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.905852     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.906469     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.907152     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.907851     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.908471     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.909149     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.909860     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.910492     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.911254     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.911941     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.912572     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.913269     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.914099     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.914866     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.915524     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.916362     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.917442     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.918527     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.919306     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.919959     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.922141     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.934911     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466501.940880     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m602/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 513ms/step - accuracy: 0.2171 - auc_7: 0.7366 - f1_score: 0.0126 - loss: 4.4075 - mcc: 0.0359 - precision_7: 0.0063 - recall_7: 0.7427 - sensitivity: 0.7427 - specificity: 0.5436","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721466810.284551     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.2213 - auc_7: 0.7390 - f1_score: 0.0127 - loss: 4.3816 - mcc: 0.0362 - precision_7: 0.0064 - recall_7: 0.7452 - sensitivity: 0.7452 - specificity: 0.5437","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721466823.654079     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.654589     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.655043     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.656175     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.656596     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.657013     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.657413     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.657785     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.658190     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.658605     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.659010     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.659425     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.659817     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.660186     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.660567     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.660981     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.661410     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.661870     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.662270     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.662710     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.663119     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.663520     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.663953     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.664365     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.664756     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.665177     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.665583     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.665984     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.666387     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721466823.666767     108 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 566ms/step - accuracy: 0.2217 - auc_7: 0.7392 - f1_score: 0.0127 - loss: 4.3793 - mcc: 0.0362 - precision_7: 0.0064 - recall_7: 0.7455 - sensitivity: 0.7455 - specificity: 0.5437 - val_accuracy: 0.7638 - val_auc_7: 0.9869 - val_f1_score: 0.0172 - val_loss: 1.0655 - val_mcc: 0.0689 - val_precision_7: 0.0087 - val_recall_7: 0.9929 - val_sensitivity: 0.9929 - val_specificity: 0.5569\nEpoch 2/30\n\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 481ms/step - accuracy: 0.8485 - auc_7: 0.9932 - f1_score: 0.0173 - loss: 0.6995 - mcc: 0.0695 - precision_7: 0.0087 - recall_7: 0.9976 - sensitivity: 0.9976 - specificity: 0.5568 - val_accuracy: 0.8089 - val_auc_7: 0.9896 - val_f1_score: 0.0172 - val_loss: 0.8249 - val_mcc: 0.0689 - val_precision_7: 0.0087 - val_recall_7: 0.9955 - val_sensitivity: 0.9955 - val_specificity: 0.5549\nEpoch 3/30\n\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 481ms/step - accuracy: 0.9536 - auc_7: 0.9982 - f1_score: 0.0173 - loss: 0.2099 - mcc: 0.0695 - precision_7: 0.0087 - recall_7: 1.0000 - sensitivity: 1.0000 - specificity: 0.5553 - val_accuracy: 0.8512 - val_auc_7: 0.9926 - val_f1_score: 0.0173 - val_loss: 0.6474 - val_mcc: 0.0695 - val_precision_7: 0.0087 - val_recall_7: 0.9978 - val_sensitivity: 0.9978 - val_specificity: 0.5569\nEpoch 4/30\n\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 481ms/step - accuracy: 0.9874 - auc_7: 0.9986 - f1_score: 0.0171 - loss: 0.0651 - mcc: 0.0688 - precision_7: 0.0086 - recall_7: 1.0000 - sensitivity: 1.0000 - specificity: 0.5502 - val_accuracy: 0.8501 - val_auc_7: 0.9917 - val_f1_score: 0.0175 - val_loss: 0.6331 - val_mcc: 0.0700 - val_precision_7: 0.0088 - val_recall_7: 0.9951 - val_sensitivity: 0.9951 - val_specificity: 0.5629\nEpoch 5/30\n\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 481ms/step - accuracy: 0.9961 - auc_7: 0.9986 - f1_score: 0.0171 - loss: 0.0236 - mcc: 0.0690 - precision_7: 0.0086 - recall_7: 1.0000 - sensitivity: 1.0000 - specificity: 0.5511 - val_accuracy: 0.8356 - val_auc_7: 0.9909 - val_f1_score: 0.0172 - val_loss: 0.7298 - val_mcc: 0.0692 - val_precision_7: 0.0087 - val_recall_7: 0.9957 - val_sensitivity: 0.9957 - val_specificity: 0.5564\nEpoch 6/30\n\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 480ms/step - accuracy: 0.9951 - auc_7: 0.9986 - f1_score: 0.0170 - loss: 0.0278 - mcc: 0.0684 - precision_7: 0.0085 - recall_7: 1.0000 - sensitivity: 1.0000 - specificity: 0.5470 - val_accuracy: 0.8450 - val_auc_7: 0.9910 - val_f1_score: 0.0170 - val_loss: 0.6992 - val_mcc: 0.0682 - val_precision_7: 0.0086 - val_recall_7: 0.9959 - val_sensitivity: 0.9959 - val_specificity: 0.5493\nEpoch 7/30\n\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 480ms/step - accuracy: 0.9945 - auc_7: 0.9987 - f1_score: 0.0168 - loss: 0.0289 - mcc: 0.0678 - precision_7: 0.0085 - recall_7: 1.0000 - sensitivity: 1.0000 - specificity: 0.5423 - val_accuracy: 0.8348 - val_auc_7: 0.9897 - val_f1_score: 0.0168 - val_loss: 0.7683 - val_mcc: 0.0676 - val_precision_7: 0.0085 - val_recall_7: 0.9957 - val_sensitivity: 0.9957 - val_specificity: 0.5450\n","output_type":"stream"}]},{"cell_type":"code","source":"execution_time_parts = []\navg_time_parts = []\n\nfor unit in [(3600, 'hours'), (60, 'minutes'), (1, 'seconds'), (0.001, 'milliseconds')]:\n    total_value = int(time_callback.total_train_time // unit[0])\n    avg_value = int(np.mean(time_callback.epoch_times) // unit[0])\n\n    if total_value > 0 or unit[0] == 0.001:\n        execution_time_parts.append((total_value, unit[1]))\n    if avg_value > 0 or unit[0] == 0.001:\n        avg_time_parts.append((avg_value, unit[1]))\n\n    time_callback.total_train_time -= total_value * unit[0]\n    time_callback.epoch_times = [time - avg_value * unit[0] for time in time_callback.epoch_times]\n\nexecution_time_string = \", \".join([\n    f\"{value:02d} {unit_str}\" for value, unit_str in execution_time_parts if value > 0\n])\n\navg_time_string = \", \".join([\n    f\"{value:02d} {unit_str}\" for value, unit_str in avg_time_parts if value > 0\n])\n\nprint(f\"Model training took {execution_time_string}\")\nprint(f\"Average time per epoch: {avg_time_string}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:43:39.874817Z","iopub.execute_input":"2024-07-20T09:43:39.875137Z","iopub.status.idle":"2024-07-20T09:43:39.886992Z","shell.execute_reply.started":"2024-07-20T09:43:39.875111Z","shell.execute_reply":"2024-07-20T09:43:39.885988Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Model training took 36 minutes, 50 seconds, 446 milliseconds\nAverage time per epoch: 05 minutes, 15 seconds, 631 milliseconds\n","output_type":"stream"}]},{"cell_type":"code","source":"_ = model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:43:39.888216Z","iopub.execute_input":"2024-07-20T09:43:39.888578Z","iopub.status.idle":"2024-07-20T09:44:11.614606Z","shell.execute_reply.started":"2024-07-20T09:43:39.888547Z","shell.execute_reply":"2024-07-20T09:44:11.613428Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 164ms/step - accuracy: 0.8523 - auc_7: 0.9919 - f1_score: 0.0175 - loss: 0.6240 - mcc: 0.0701 - precision_7: 0.0088 - recall_7: 0.9963 - sensitivity: 0.9963 - specificity: 0.5628\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721468651.545231     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721468651.545738     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1721468651.546382     110 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report\n\n# Assuming model is your trained model\n# Predict model for each class\ny_pred_prob = model.predict(test_data)\n\n# Convert probabilities to class labels\ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Convert y_test from one-hot encoded to categorical labels if needed\ny_true = np.argmax(test_data, axis=1)\n\n# Generate classification report\nreport = classification_report(y_true, y_pred)\n\n# Print the report\nprint(report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history, metric_name_list, figure_size=(10, 6)):\n    \"\"\"\n    Plots the given metrics for the training and validation sets.\n\n    Args:\n        history: a Keras History object containing the training history\n        metric_name_list: a list of strings representing the names of the metrics to plot\n        figure_size: a tuple specifying the size of the figure (width, height)\n\n    Returns:\n        None\n    \"\"\"\n    # Check if history is a valid Keras History object\n    if not isinstance(history, type(tf.keras.callbacks.History())):\n        raise ValueError(\"Invalid Keras History object provided.\")\n\n    num_metrics = len(metric_name_list)\n\n    # Create subplots\n    figure, axes = plt.subplots(num_metrics, figsize=(figure_size[0], figure_size[1] * num_metrics))\n\n    # Define x-axis range\n    rng = range(1, len(history.history[metric_name_list[0]]) + 1)\n\n    for ax, metric_name in zip(axes, metric_name_list):\n        # Check if the metric exists in the history\n        if metric_name not in history.history:\n            raise ValueError(f\"Metric '{metric_name}' not found in the training history.\")\n\n        metric = history.history[metric_name]\n        v_metric = history.history.get(f\"val_{metric_name}\", None)\n\n        # Plot training metric\n        ax.plot(rng, metric, label=metric_name)\n\n        # Plot validation metric if available\n        if v_metric is not None:\n            ax.plot(rng, v_metric, label=f\"val_{metric_name}\")\n\n        ax.legend()\n        ax.set_xlabel(\"Epochs\")\n\n        # Set y-axis label and title\n        ylabel = metric_name.upper() if metric_name in (\"auc\", \"mcc\") else metric_name.capitalize()\n        ax.set_ylabel(ylabel)\n        ax.set_title(f\"{ylabel} vs Epochs\")\n\n        # Set y-axis limits\n        max_loss = max(max(metric), max(v_metric)) if v_metric is not None else max(metric)\n        min_loss = min(min(metric), min(v_metric)) if v_metric is not None else min(metric)\n        y_max = math.ceil(max_loss)\n\n        if min_loss > 0 or max_loss > 1:\n            ax.set_ylim(0, y_max)\n        else:\n            ax.set_ylim(min_loss, y_max)\n\n        ax.grid(True, linestyle='--', alpha=0.5)\n        ax.set_xlim(1, len(metric))\n\n    plt.tight_layout()\n    plt.show()\n\nmetric_names = [\"loss\", \"accuracy\", \"precision_1\", \"recall_1\", \"f1_score\",\n                \"specificity\", \"sensitivity\", \"mcc\", \"auc_1\"]\nplot_metrics(history, metric_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    ","metadata":{},"execution_count":null,"outputs":[]}]}